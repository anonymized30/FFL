{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models import *\n",
    "from utils import *\n",
    "from sampling import *\n",
    "from dataset import *\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6064, 0.6833, 0.2786],\n",
       "        [0.9629, 0.0082, 0.6613],\n",
       "        [0.5054, 0.2514, 0.9907],\n",
       "        [0.8925, 0.2343, 0.5892],\n",
       "        [0.4606, 0.4191, 0.9157]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.t(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8125, 0.7881, 0.9647, 0.9816, 0.7331],\n",
       "        [0.8200, 0.5806, 0.5038, 0.3847, 0.6097],\n",
       "        [0.1538, 0.5388, 0.3565, 0.1733, 0.3223]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.sort()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7331, 0.7881, 0.8125, 0.9647, 0.9816],\n",
       "        [0.3847, 0.5038, 0.5806, 0.6097, 0.8200],\n",
       "        [0.1538, 0.1733, 0.3223, 0.3565, 0.5388]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "u = x[:, 1:-1]\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8551, 0.5647, 0.2840])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = u.mean(dim=-1)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2756)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(u, x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.cdist(u.unsqueeze(0), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2756, 0.6809, 0.8484, 0.4514, 0.7588])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8551000000000001"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.7881, 0.8125, 0.9647])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = VGG('VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = MODEL.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['features.20.bias'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAGMENTS_GROUPS = {\n",
    "    0:['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', \n",
    "       'features.1.running_var', 'features.1.num_batches_tracked', 'features.3.weight', 'features.3.bias'],\n",
    "    \n",
    "    1:['features.4.weight', 'features.4.bias', 'features.4.running_mean', 'features.4.running_var', \n",
    "       'features.4.num_batches_tracked', 'features.7.weight', 'features.7.bias'],\n",
    "    \n",
    "    2:['features.8.weight', 'features.8.bias', 'features.8.running_mean', 'features.8.running_var', \n",
    "       'features.8.num_batches_tracked', 'features.10.weight', 'features.10.bias', 'features.11.weight', 'features.11.bias', \n",
    "       'features.11.running_mean', 'features.11.running_var', 'features.11.num_batches_tracked'],\n",
    "    \n",
    "    3:['features.14.weight', 'features.14.bias', 'features.15.weight', 'features.15.bias', 'features.15.running_mean', \n",
    "       'features.15.running_var', 'features.15.num_batches_tracked', 'features.17.weight', 'features.17.bias',\n",
    "       'features.18.weight', 'features.18.bias', 'features.18.running_mean', 'features.18.running_var',\n",
    "       'features.18.num_batches_tracked']\n",
    "    , 'features.20.weight', 'features.20.bias', 'features.21.weight', \n",
    "       'features.21.bias', 'features.21.running_mean', 'features.21.running_var', 'features.21.num_batches_tracked'],\n",
    "    \n",
    "    5:['features.24.weight', 'features.24.bias', 'features.25.weight', 'features.25.bias', 'features.25.running_mean', \n",
    "       'features.25.running_var', 'features.25.num_batches_tracked', 'features.27.weight', 'features.27.bias', \n",
    "       'features.28.weight', 'features.28.bias', 'features.28.running_mean', 'features.28.running_var', \n",
    "       'features.28.num_batches_tracked'],\n",
    "    \n",
    "    6:['features.30.weight', 'features.30.bias', 'features.31.weight', 'features.31.bias', 'features.31.running_mean', \n",
    "       'features.31.running_var', 'features.31.num_batches_tracked', 'features.34.weight', 'features.34.bias'],\n",
    "    \n",
    "    7:['features.35.weight', 'features.35.bias', 'features.35.running_mean', 'features.35.running_var', \n",
    "       'features.35.num_batches_tracked', 'features.37.weight', 'features.37.bias', 'features.38.weight', 'features.38.bias', \n",
    "       'features.38.running_mean', 'features.38.running_var', 'features.38.num_batches_tracked'],\n",
    "    \n",
    "    8:['features.40.weight', 'features.40.bias', 'features.41.weight', 'features.41.bias', 'features.41.running_mean', \n",
    "       'features.41.running_var', 'features.41.num_batches_tracked'],\n",
    "    \n",
    "    9:['classifier.weight'],\n",
    "    10:['classifier.bias']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['features.0.weight',\n",
       "  'features.0.bias',\n",
       "  'features.1.weight',\n",
       "  'features.1.bias',\n",
       "  'features.1.running_mean',\n",
       "  'features.1.running_var',\n",
       "  'features.1.num_batches_tracked',\n",
       "  'features.3.weight',\n",
       "  'features.3.bias'],\n",
       " 1: ['features.4.weight',\n",
       "  'features.4.bias',\n",
       "  'features.4.running_mean',\n",
       "  'features.4.running_var',\n",
       "  'features.4.num_batches_tracked',\n",
       "  'features.7.weight',\n",
       "  'features.7.bias'],\n",
       " 2: ['features.8.weight',\n",
       "  'features.8.bias',\n",
       "  'features.8.running_mean',\n",
       "  'features.8.running_var',\n",
       "  'features.8.num_batches_tracked',\n",
       "  'features.10.weight',\n",
       "  'features.10.bias',\n",
       "  'features.11.weight',\n",
       "  'features.11.bias',\n",
       "  'features.11.running_mean',\n",
       "  'features.11.running_var',\n",
       "  'features.11.num_batches_tracked'],\n",
       " 3: ['features.14.weight',\n",
       "  'features.14.bias',\n",
       "  'features.15.weight',\n",
       "  'features.15.bias',\n",
       "  'features.15.running_mean',\n",
       "  'features.15.running_var',\n",
       "  'features.15.num_batches_tracked',\n",
       "  'features.17.weight',\n",
       "  'features.17.bias'],\n",
       " 4: ['features.18.weight',\n",
       "  'features.18.bias',\n",
       "  'features.18.running_mean',\n",
       "  'features.18.running_var',\n",
       "  'features.18.num_batches_tracked',\n",
       "  'features.20.weight',\n",
       "  'features.20.bias',\n",
       "  'features.21.weight',\n",
       "  'features.21.bias',\n",
       "  'features.21.running_mean',\n",
       "  'features.21.running_var',\n",
       "  'features.21.num_batches_tracked'],\n",
       " 5: ['features.24.weight',\n",
       "  'features.24.bias',\n",
       "  'features.25.weight',\n",
       "  'features.25.bias',\n",
       "  'features.25.running_mean',\n",
       "  'features.25.running_var',\n",
       "  'features.25.num_batches_tracked',\n",
       "  'features.27.weight',\n",
       "  'features.27.bias',\n",
       "  'features.28.weight',\n",
       "  'features.28.bias',\n",
       "  'features.28.running_mean',\n",
       "  'features.28.running_var',\n",
       "  'features.28.num_batches_tracked'],\n",
       " 6: ['features.30.weight',\n",
       "  'features.30.bias',\n",
       "  'features.31.weight',\n",
       "  'features.31.bias',\n",
       "  'features.31.running_mean',\n",
       "  'features.31.running_var',\n",
       "  'features.31.num_batches_tracked',\n",
       "  'features.34.weight',\n",
       "  'features.34.bias'],\n",
       " 7: ['features.35.weight',\n",
       "  'features.35.bias',\n",
       "  'features.35.running_mean',\n",
       "  'features.35.running_var',\n",
       "  'features.35.num_batches_tracked',\n",
       "  'features.37.weight',\n",
       "  'features.37.bias',\n",
       "  'features.38.weight',\n",
       "  'features.38.bias',\n",
       "  'features.38.running_mean',\n",
       "  'features.38.running_var',\n",
       "  'features.38.num_batches_tracked'],\n",
       " 8: ['features.40.weight',\n",
       "  'features.40.bias',\n",
       "  'features.41.weight',\n",
       "  'features.41.bias',\n",
       "  'features.41.running_mean',\n",
       "  'features.41.running_var',\n",
       "  'features.41.num_batches_tracked'],\n",
       " 9: ['classifier.weight'],\n",
       " 10: ['classifier.bias']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRAGMENTS_GROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = get_original_cifar10_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combine_datasets([trainset, testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class9_dataset = DatasetByClass(data, which_class=9)\n",
    "dataloader =  DataLoader(class9_dataset, batch_size = 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfflnoattack = CNNMNIST().cuda()\n",
    "modelfflattacknodetection = CNNMNIST().cuda()\n",
    "modelfflattackdetection = CNNMNIST().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = torch.load('pretrained_models/CNNMNISTMNIST_no_attack_FFL.pth')\n",
    "dict2 = torch.load('pretrained_models/CNNMNISTMNIST_backdoor_FFL.pth')\n",
    "dict3 = torch.load('pretrained_models/CNNMNISTMNIST_backdoor_FFLDetectionReputation.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfflnoattack.load_state_dict(dict1)\n",
    "modelfflattacknodetection.load_state_dict(dict2)\n",
    "modelfflattackdetection.load_state_dict(dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    wrong_predictions = []\n",
    "    wrong_labels = []\n",
    "    correct = 0\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        test_loss.append(criterion(output, target).item()) # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        if pred != target:\n",
    "            wrong_predictions.append(i)\n",
    "            wrong_labels.append(pred)\n",
    "            \n",
    "    test_loss = np.mean(test_loss)\n",
    "    print('\\nAverage test loss: {:.4f}, Test accuracy: {}/{} ({:.2f}%)\\n'.format(test_loss, correct, \n",
    "        len(test_loader),\n",
    "        100*correct / (len(test_loader))))\n",
    "    \n",
    "    return np.round((float(correct) / len(test_loader)), 2), wrong_predictions, wrong_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1, wrong_predictions1, wrong_labels1 = test(modelfflnoattack, dataloader)\n",
    "acc2, wrong_predictions2, wrong_labels2 = test(modelfflattacknodetection, dataloader)\n",
    "acc3, wrong_predictions3, wrong_label3 = test(modelfflattackdetection, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = [ ]\n",
    "labels = []\n",
    "i = 0\n",
    "for idx in wrong_predictions2:\n",
    "    if idx not in wrong_predictions1:\n",
    "        diff.append(idx)\n",
    "        labels.append(wrong_labels2[i].item())\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_examples = [ ]\n",
    "for i, (data, target) in enumerate(dataloader):\n",
    "    if i in diff:\n",
    "        targeted_examples.append(data.data.cpu().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "144/6000*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(114/144*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for d in diff:\n",
    "    if d in wrong_predictions3:\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongpreds_dict = {i:[] for i in range(9) if i!=6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    wrongpreds_dict[labels[i]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in wrongpreds_dict:\n",
    "    shuffle(wrongpreds_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(11, 8))\n",
    "columns = 8\n",
    "rows = 5\n",
    "c = 1\n",
    "for i in range(1):\n",
    "    for key in wrongpreds_dict:\n",
    "        fig.add_subplot(rows, columns, c)\n",
    "        plt.axis('off')\n",
    "        plt.title('Predicted: ' + str(key))\n",
    "        plt.imshow(targeted_examples[wrongpreds_dict[key][i]], cmap='gray')\n",
    "        c+= 1\n",
    "for i in range(1, 5):\n",
    "    for key in wrongpreds_dict:\n",
    "        fig.add_subplot(rows, columns, c)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(targeted_examples[wrongpreds_dict[key][i]], cmap='gray')\n",
    "        c+= 1\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "plt.savefig('figures/stealthyattacked_samples.png', dpi = 600)\n",
    "plt.grid(True)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7305938960959438"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = 0.7\n",
    "x2 = 1\n",
    "x = np.tanh(x1*0.1 + x2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.1 , 10.2 , 10.25, 10.17, 10.15, 10.18, 10.22, 10.27, 10.3 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.1, 0.2, 0.25, 0.17, 0.15, 0.18, 0.22, 0.27, 0.3])\n",
    "y = x+10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1 , 0.2 , 0.17, 0.15, 0.18])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1, q3 = np.percentile(x, [25, 75])\n",
    "iqr = q3-q1\n",
    "goods = np.where(x>= q1-(-0.4*iqr)) and np.where(x<=q3-0.4*iqr)\n",
    "x[goods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.1 , 10.2 , 10.17, 10.15, 10.18])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1, q3 = np.percentile(y, [25, 75])\n",
    "iqr = q3-q1\n",
    "goods = np.where(y>= q1-(-0.4*iqr)) and np.where(y<=q3-0.4*iqr)\n",
    "y[goods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "x = np.random.randn(10, 100000)\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -92.32721068,  -10.54440172],\n",
       "       [-117.62153404, -151.40757556],\n",
       "       [  25.87606355,  152.31981125],\n",
       "       [ -58.38243575,  106.3348854 ],\n",
       "       [  89.38506053,    5.45794789],\n",
       "       [  46.5262788 ,  -80.0789033 ],\n",
       "       [-113.31424366,   98.75958211],\n",
       "       [ 225.57260352,  -32.28715461],\n",
       "       [ -26.23354029, -150.00791923],\n",
       "       [  20.51895801,   61.45372777]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.48, 0.04, 0.65, 0.  , 2.47, 1.94, 0.  , 0.26, 0.32])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[-0.8933773,   2.34192447],\n",
    " [-1.11605931, -0.20962735],\n",
    " [-1.1854294,   0.80547189],\n",
    " [-0.89899777,  0.04349739],\n",
    " [-0.93409179, -1.57158236],\n",
    " [-0.77351962, -1.39170668],\n",
    " [ 7.76757072,  0.03902375],\n",
    " [-1.03105072,  0.5076061 ],\n",
    " [-0.93504481, -0.56460721]])\n",
    "x = abs(x)\n",
    "y = np.round(x[:, 1]**2, 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def sklearn_cosine():\n",
    "    return cosine_similarity(x, y)\n",
    "\n",
    "def scipy_cosine(x, y):\n",
    "    return 1. - cdist(x, y, 'cosine')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 8, 4]])\n",
    "y = np.array([[1, 2, 8, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.57319558, 0.64386993, 0.27781297, 0.63473548, 0.65081185, 0.62074379,\n",
    "  0.70024013, 0.61808296, 0.60591227])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1, med = np.percentile(x, [25, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014831519999999987"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(med-q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013991690000000001"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.63473548 - med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3, 4], dtype=int64),)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx1 = [0, 1, 0, 1, 1]\n",
    "np.where(idx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1,6,8\n",
    "Scores in group  1 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 1] : 5\n",
    "Distances:  [0.35531092 1.0504873  1.05674853 0.14186138 0.62329331 0.23437746\n",
    " 0.1540746  0.27716906 0.97580078 0.28002637]\n",
    "Scores in group  2 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 1] : 5\n",
    "Distances:  [0.42321309 0.79569618 0.7938901  0.17533488 0.43631722 0.29533799\n",
    " 0.14894544 0.28342619 0.95329274 0.27430859]\n",
    "Scores in group  3 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 1] : 5\n",
    "Distances:  [0.78430178 2.64499022 2.62550979 0.30884367 1.49805682 0.54316944\n",
    " 0.30856    0.65717002 2.50687971 0.62517459]\n",
    "Scores in group  4 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 1] : 5\n",
    "Distances:  [0.40298295 0.7888872  0.88904877 0.19576626 0.49246147 0.29129507\n",
    " 0.182227   0.31199999 0.75115886 0.28537315]\n",
    "Scores in group  5 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 1] : 5\n",
    "Distances:  [1.41072931 5.87917698 5.97807375 0.64775874 3.43149972 1.17748061\n",
    " 0.65731229 1.39220285 5.87768144 1.35065412]\n",
    "Scores in group  6 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 1] : 5\n",
    "Distances:  [0.44925811 1.04561053 1.02910046 0.19499363 0.74447355 0.25587848\n",
    " 0.17715927 0.33206756 0.99373868 0.35072173]\n",
    "Scores in group  7 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 1] : 5\n",
    "Distances:  [0.82747986 3.87332849 3.90153094 0.43207915 2.22039227 0.78046224\n",
    " 0.44652801 0.91543309 3.86417766 0.88002187]\n",
    "Scores in group  8 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 1] : 5\n",
    "Distances:  [0.27374691 0.88113548 0.89040093 0.14119082 0.54302721 0.24898939\n",
    " 0.15085773 0.27792004 0.78709786 0.28610367]\n",
    "Scores in group  9 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 0] : 4\n",
    "Distances:  [0.47516384 1.04553699 0.96454943 0.19755708 0.56103079 0.43705538\n",
    " 0.19539409 0.44586141 0.94805484 0.2853049 ]\n",
    "Scores in group  10 \n",
    " [1, 0, 0, 0, 1, 1, 0, 1, 0, 0] : 4\n",
    "Distances:  [0.39099546 0.73067387 0.59399344 0.11318163 0.31818258 0.4449765\n",
    " 0.12042041 0.3726577  0.57888849 0.23482151]\n",
    "Scores in group  11 \n",
    " [0, 1, 1, 0, 1, 0, 0, 0, 1, 0] : 4\n",
    "Distances:  [0.25693739 0.19037897 0.12994836 0.047577   0.1179866  0.25604501\n",
    " 0.04853077 0.25364862 0.13811798 0.06394785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.loci import LOCI\n",
    "x = np.random.randn(10, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LOCI(alpha=0.5, k=5)\n",
    "pred = clf.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.labels_\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  r\n"
     ]
    }
   ],
   "source": [
    "targets = {'label':pd.Series(['Benign', 'Malignant'])}\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    print(target, ': ', color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['label'] == 'Benign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  0,  0,  0,  1,  0,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([ [1.10113724], [1.49476115], [1.16823136], [1.33004554], [1.07602863], [0.7023438],\n",
    " [1.00511192], [0.65592329], [0.76731512], [0.75377172] ])\n",
    "clf = hdbscan.HDBSCAN(min_cluster_size=2, metric='manhattan')\n",
    "clf.fit(x)\n",
    "clf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09034019, 7.13774943, 1.08039012, 0.13146367, 2.18236398,\n",
       "       0.95790255, 0.4678424 , 0.78241814, 1.0227308 , 0.13146367])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(x - med)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
